package se.alipsa.jparq;

import java.io.File;
import java.io.IOException;
import java.sql.Connection;
import java.sql.PreparedStatement;
import java.sql.ResultSet;
import java.sql.SQLException;
import java.sql.SQLFeatureNotSupportedException;
import java.sql.SQLWarning;
import java.sql.Statement;
import net.sf.jsqlparser.expression.Expression;
import org.apache.avro.Schema;
import org.apache.avro.generic.GenericRecord;
import org.apache.commons.lang3.concurrent.BasicThreadFactory;
import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.fs.Path;
import org.apache.parquet.avro.AvroReadSupport;
import org.apache.parquet.filter2.compat.FilterCompat;
import org.apache.parquet.hadoop.ParquetReader;
import se.alipsa.jparq.engine.ParquetFilterBuilder;
import se.alipsa.jparq.engine.ParquetSchemas;
import se.alipsa.jparq.engine.ProjectionFields;
import se.alipsa.jparq.engine.SqlParser;

/** An implementation of the java.sql.Statement interface. */
@SuppressWarnings({
    "checkstyle:AbbreviationAsWordInName", "checkstyle:OverloadMethodsDeclarationOrder"
})
public class JParqStatement extends BasicThreadFactory.Builder implements Statement {

  private final JParqConnection conn;
  private String currentSql;
  private JParqResultSet currentRs;

  /**
   * Constructor for JParqStatement.
   *
   * @param conn
   *          the JParqConnection
   */
  public JParqStatement(JParqConnection conn) {
    this.conn = conn;
  }

  PreparedStatement prepare(String sql) throws SQLException {
    this.currentSql = sql;
    return new JParqPreparedStatement(this, sql);
  }

  public JParqConnection getConn() {
    return conn;
  }

  public String getCurrentSql() {
    return currentSql;
  }

  public JParqResultSet getCurrentRs() {
    return currentRs;
  }

  @SuppressWarnings({
      "PMD.CloseResource", "PMD.AvoidCatchingGenericException", "PMD.EmptyCatchBlock"
  })
  @Override
  public ResultSet executeQuery(String sql) throws SQLException {
    this.currentSql = sql;
    SqlParser.Select select = SqlParser.parseSelect(sql);
    File file = conn.tableFile(select.table());

    Configuration conf = new Configuration(false);
    conf.setBoolean("parquet.filter.statistics.enabled", true);
    conf.setBoolean("parquet.read.filter.columnindex.enabled", true);
    conf.setBoolean("parquet.filter.dictionary.enabled", true);

    Path path = new Path(file.toURI());

    // Read file Avro schema if present
    Schema avroSchema = null;
    try {
      avroSchema = ParquetSchemas.readAvroSchema(path, conf);
    } catch (IOException ignore) {
      // no schema -> no pushdown/projection
    }

    // ---- Requested projection (SELECT columns only) ----
    if (avroSchema != null) {
      java.util.Set<String> selectCols = ProjectionFields.fromSelect(select); // null for *
      if (selectCols != null) { // i.e., not SELECT *
        Schema requested = ParquetSchemas.requestedSubset(avroSchema, selectCols);
        if (requested != null) {
          AvroReadSupport.setRequestedProjection(conf, requested);
        }
      }
    }

    // ---- Filter pushdown + residual ----
    Expression residual = null;
    ParquetReader<GenericRecord> reader;
    try {
      ParquetReader.Builder<GenericRecord> builder = ParquetReader.<GenericRecord>builder(new AvroReadSupport<>(), path)
          .withConf(conf);

      if (avroSchema != null && select.where() != null) {
        var maybePred = ParquetFilterBuilder.build(avroSchema, select.where());
        if (maybePred.isPresent()) {
          builder = builder.withFilter(FilterCompat.get(maybePred.get()));
        }
        residual = ParquetFilterBuilder.residual(avroSchema, select.where()); // null if fully pushed
      } else {
        residual = select.where(); // nothing pushed
      }

      reader = builder.build();
    } catch (Exception e) {
      throw new SQLException("Failed to open parquet file: " + file, e);
    }

    this.currentRs = new JParqResultSet(reader, select, file.getName(), residual);
    return currentRs;
  }

  // --- Boilerplate / no-ops for read-only driver ---
  @Override
  public int executeUpdate(String sql) throws SQLException {
    throw new SQLFeatureNotSupportedException();
  }

  @Override
  public int executeUpdate(String sql, int autoGeneratedKeys) throws SQLException {
    throw new SQLFeatureNotSupportedException();
  }

  @Override
  public int executeUpdate(String sql, int[] columnIndexes) throws SQLException {
    throw new SQLFeatureNotSupportedException();
  }

  @Override
  public int executeUpdate(String sql, String[] columnNames) throws SQLException {
    throw new SQLFeatureNotSupportedException();
  }

  @Override
  public void close() {
    try {
      if (currentRs != null) {
        currentRs.close();
      }
    } catch (SQLException ignored) {
      // Ignore
    }
  }

  @Override
  public int getMaxFieldSize() {
    return 0;
  }

  @Override
  public void setMaxFieldSize(int max) {
  }

  @Override
  public int getMaxRows() {
    return 0;
  }

  @Override
  public void setMaxRows(int max) {
  }

  @Override
  public void setEscapeProcessing(boolean enable) {
  }

  @Override
  public int getQueryTimeout() {
    return 0;
  }

  @Override
  public void setQueryTimeout(int seconds) {
  }

  @Override
  public void cancel() {
  }

  @Override
  public SQLWarning getWarnings() {
    return null;
  }

  @Override
  public void clearWarnings() {
  }

  @Override
  public void setCursorName(String name) {
  }

  @Override
  public boolean execute(String sql) throws SQLException {
    executeQuery(sql);
    return true;
  }

  @Override
  public boolean execute(String sql, int autoGeneratedKeys) throws SQLException {
    throw new SQLFeatureNotSupportedException();
  }

  @Override
  public boolean execute(String sql, int[] columnIndexes) throws SQLException {
    throw new SQLFeatureNotSupportedException();
  }

  @Override
  public boolean execute(String sql, String[] columnNames) throws SQLException {
    throw new SQLFeatureNotSupportedException();
  }

  @Override
  public ResultSet getResultSet() {
    return currentRs;
  }

  @Override
  public int getUpdateCount() {
    return -1;
  }

  @Override
  public boolean getMoreResults() {
    return false;
  }

  @Override
  public boolean getMoreResults(int current) throws SQLException {
    return false;
  }

  @Override
  public void setFetchDirection(int direction) {
    // Ignore
  }

  @Override
  public int getFetchDirection() {
    return ResultSet.FETCH_FORWARD;
  }

  @Override
  public void setFetchSize(int rows) {
  }

  @Override
  public int getFetchSize() {
    return 0;
  }

  @Override
  public int getResultSetConcurrency() {
    return ResultSet.CONCUR_READ_ONLY;
  }

  @Override
  public int getResultSetType() {
    return ResultSet.TYPE_FORWARD_ONLY;
  }

  @Override
  public void addBatch(String sql) {
  }

  @Override
  public void clearBatch() throws SQLException {
  }

  @Override
  public int[] executeBatch() throws SQLException {
    return new int[0];
  }

  @Override
  public Connection getConnection() throws SQLException {
    return null;
  }

  @Override
  public ResultSet getGeneratedKeys() throws SQLException {
    return null;
  }

  @Override
  public int getResultSetHoldability() throws SQLException {
    return 0;
  }

  @Override
  public boolean isClosed() throws SQLException {
    return false;
  }

  @Override
  public void setPoolable(boolean poolable) throws SQLException {
  }

  @Override
  public boolean isPoolable() throws SQLException {
    return false;
  }

  @Override
  public void closeOnCompletion() throws SQLException {
  }

  @Override
  public boolean isCloseOnCompletion() throws SQLException {
    return false;
  }

  @Override
  public <T> T unwrap(Class<T> iface) throws SQLException {
    return null;
  }

  @Override
  public boolean isWrapperFor(Class<?> iface) throws SQLException {
    return false;
  }
}